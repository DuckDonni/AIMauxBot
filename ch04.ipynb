{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "95586083-c189-44e0-9a87-d38fb84e6e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 1024,\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1, \n",
    "    \"qkv_bias\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1bb7db06-ead5-406e-af04-8f0bc4878b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class DummyGPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        \n",
    "        # Use a placeholder for TransformerBlock\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[DummyTransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        \n",
    "        # Use a placeholder for LayerNorm\n",
    "        self.final_norm = DummyLayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class DummyTransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        # A simple placeholder\n",
    "\n",
    "    def forward(self, x):\n",
    "        # This block does nothing and just returns its input.\n",
    "        return x\n",
    "\n",
    "\n",
    "class DummyLayerNorm(nn.Module):\n",
    "    def __init__(self, normalized_shape, eps=1e-5):\n",
    "        super().__init__()\n",
    "        # The parameters here are just to mimic the LayerNorm interface.\n",
    "\n",
    "    def forward(self, x):\n",
    "        # This layer does nothing and just returns its input.\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e28b7276-0cfa-4d73-a04a-6460baf75b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "batch = []\n",
    "\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "batch = torch.stack(batch, dim=0)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f4787630-732a-40a1-b86c-ea9681b9c3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[-0.9289,  0.2748, -0.7557,  ..., -1.6070,  0.2702, -0.5888],\n",
      "         [-0.4476,  0.1726,  0.5354,  ..., -0.3932,  1.5285,  0.8557],\n",
      "         [ 0.5680,  1.6053, -0.2155,  ...,  1.1624,  0.1380,  0.7425],\n",
      "         [ 0.0447,  2.4787, -0.8843,  ...,  1.3219, -0.0864, -0.5856]],\n",
      "\n",
      "        [[-1.5474, -0.0542, -1.0571,  ..., -1.8061, -0.4494, -0.6747],\n",
      "         [-0.8422,  0.8243, -0.1098,  ..., -0.1434,  0.2079,  1.2046],\n",
      "         [ 0.1355,  1.1858, -0.1453,  ...,  0.0869, -0.1590,  0.1552],\n",
      "         [ 0.1666, -0.8138,  0.2307,  ...,  2.5035, -0.3055, -0.3083]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = DummyGPTModel(cfg=GPT_CONFIG_124M)\n",
    "# The outputs of the linear layer of a model are called logits\n",
    "logits = model(batch)\n",
    "print(\"Output shape:\", logits.shape)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0587670f-9834-4120-bc43-e547933c54ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6504966f-93d5-4e25-8d8c-381ebaa2296c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b714ae66-cd0b-4320-aad9-769be4f37d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[     0.3374,     -0.1778,     -0.3035,     -0.5880,      0.3486,\n",
       "              0.6603,     -0.2196,     -0.3792,      0.7671,     -1.1925,\n",
       "              0.6984,     -1.4097,      0.1794,      1.8951,      0.4954,\n",
       "              0.2692,     -0.0770,     -1.0205,     -0.1690,      0.9178,\n",
       "              1.5810,      1.3010,      1.2753,     -0.2010,      0.4965,\n",
       "             -1.5723,      0.9666,     -1.1481,     -1.1589,      0.3255,\n",
       "             -0.6315,     -2.8400,     -1.3250,      0.1784,     -2.1338,\n",
       "              1.0524,     -0.3885,     -0.9343,     -0.4991,     -1.0867,\n",
       "              0.8805,      1.5542,      0.6266,     -0.1755,      0.0983,\n",
       "             -0.0935,      0.2662,     -0.5850,      0.8768,      1.6221,\n",
       "             -1.4779,      1.1331,     -1.2203,      1.3139,      1.0533,\n",
       "              0.1388,      2.2473,     -0.8036,     -0.2808,      0.7697,\n",
       "             -0.6596,     -0.7979,      0.1838,      0.2293,      0.5146,\n",
       "              0.9938,     -0.2587,     -1.0826,     -0.0444,      1.6236,\n",
       "             -2.3229,      1.0878,      0.6716,      0.6933,     -0.9487,\n",
       "             -0.0765,     -0.1526,      0.1167,      0.4403,     -1.4465,\n",
       "              0.2553,     -0.5496,      1.0042,      0.8272,     -0.3948,\n",
       "              0.4892,     -0.2168,     -1.7472,     -1.6025,     -1.0764,\n",
       "              0.9031,     -0.7218,     -0.5951,     -0.7112,      0.6230,\n",
       "             -1.3729,     -2.2150,     -1.3193,     -2.0915,      0.9629],\n",
       "        [    -0.0319,     -0.4790,      0.7668,      0.0275,      1.9929,\n",
       "              1.3708,     -0.5009,     -0.2793,     -2.0628,      0.0064,\n",
       "             -0.9896,      0.7016,     -0.9405,     -0.4681,      1.0322,\n",
       "             -0.2830,      0.4928,     -0.0141,     -0.2747,     -0.7641,\n",
       "              1.3966,     -0.9949,     -0.0016,      1.2471,     -0.0771,\n",
       "              1.2774,     -1.4596,     -2.1595,     -0.2582,     -2.0407,\n",
       "             -0.8016,     -0.8183,     -1.1820,     -0.2877,     -0.6043,\n",
       "              0.6002,     -1.4053,     -0.5922,     -0.2548,      1.1517,\n",
       "             -0.0179,      0.4264,     -0.7657,     -0.0545,     -1.2743,\n",
       "              0.4513,     -0.2280,      0.9224,      0.2056,     -0.4970,\n",
       "              0.5821,      0.2053,     -0.3018,     -0.6703,     -0.6171,\n",
       "             -0.8334,      0.4839,     -0.1349,      0.2119,     -0.8714,\n",
       "              0.6851,      2.0024,     -0.5469,      1.6014,     -2.2577,\n",
       "             -1.8009,      0.7015,      0.5703,     -1.1766,     -2.0524,\n",
       "              0.1132,      1.4353,      0.0883,     -1.2037,      1.0964,\n",
       "              2.4210,      0.1538,     -0.4452,      0.5503,      0.0658,\n",
       "              0.6805,      1.2064,      1.6250,      0.3459,     -0.8484,\n",
       "              0.5323,     -0.9344,     -0.8431,     -0.1346,      0.4680,\n",
       "             -0.7952,     -0.9178,      0.4187,     -1.1123,      1.1227,\n",
       "              0.2646,     -0.4698,      1.0866,     -0.8892,      0.7647]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "batch_example = torch.randn(2, 100)\n",
    "\n",
    "batch_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9e0d7cbc-31e4-4e75-9181-68929424e1a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.7596, 0.5588, 0.0000, 0.0000, 0.5382, 0.0000, 0.2054,\n",
       "         0.0000, 0.5107, 0.1604, 0.3479, 0.6378, 0.8569, 0.0000, 0.0423, 0.0516,\n",
       "         0.4414, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3212, 0.0000, 0.0000,\n",
       "         0.8447, 0.1592, 0.0000, 0.0000, 0.6698, 0.0550, 0.0000, 0.2423, 0.0000,\n",
       "         0.0000, 0.0313, 0.3183, 0.0396, 0.4979, 0.4290, 0.0698, 0.2870, 0.1595,\n",
       "         0.7883, 0.0000, 0.1823, 0.0000, 0.0000, 0.9425, 0.5040, 0.6615, 0.0000,\n",
       "         0.0000, 0.0718, 0.5367, 0.3890, 0.0000, 0.0000, 0.6538, 0.6955, 0.8314,\n",
       "         0.0000, 0.0000, 0.8936, 0.0000, 0.0000, 0.9103, 0.0000, 0.9734, 0.0000,\n",
       "         0.1423, 0.0000, 0.4092, 0.0000, 0.0000, 0.0000, 0.2176, 0.0000, 0.5356,\n",
       "         0.0000, 0.1020, 0.0000, 0.6683, 0.7368, 0.5873, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.3593, 0.0000, 0.0000, 0.0464, 0.0000, 0.2353, 0.5605, 0.0000,\n",
       "         0.1268],\n",
       "        [0.0000, 0.0000, 1.0697, 0.1866, 0.6376, 0.9650, 0.0000, 0.0000, 0.0000,\n",
       "         1.1453, 0.3040, 0.2498, 0.0000, 0.0000, 0.2051, 0.1343, 0.0693, 0.0000,\n",
       "         0.0000, 0.2330, 0.0996, 0.0000, 0.5045, 1.2911, 0.6735, 0.4501, 0.0000,\n",
       "         1.0002, 0.5469, 0.1638, 0.0000, 0.2817, 0.1181, 0.0000, 0.2630, 0.6913,\n",
       "         0.0000, 0.0000, 0.0000, 0.4561, 0.0000, 0.3444, 0.2869, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.9086, 0.6165, 0.0000, 0.6380, 0.0000, 0.0000,\n",
       "         0.5131, 0.0000, 0.0000, 0.2567, 0.0000, 0.9057, 0.2841, 0.0000, 0.2211,\n",
       "         0.0300, 0.0000, 0.0000, 0.0000, 0.0000, 0.2508, 0.0000, 0.0000, 0.5888,\n",
       "         0.1723, 0.4376, 0.5098, 1.0247, 0.0924, 0.0000, 0.0000, 0.5703, 0.0000,\n",
       "         0.2202, 0.4794, 0.2886, 0.0000, 0.0563, 0.0000, 0.1561, 0.0000, 0.4994,\n",
       "         0.0402, 0.2817, 0.0000, 0.0000, 0.4951, 0.3381, 0.6438, 0.0000, 0.3482,\n",
       "         1.8551]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = nn.Sequential(nn.Linear(100, 100), nn.ReLU())\n",
    "\n",
    "out = layer(batch_example)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "17184f0e-de3c-446c-b866-8be0022cbdf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2300],\n",
       "        [0.2609]], grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -1 ensures every row is gathered regardless of size\n",
    "\n",
    "\n",
    "mean = out.mean(dim=-1, keepdim = True)\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cbc4ea8e-8856-46e8-8f26-aa9934d224b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0901],\n",
       "        [0.1261]], grad_fn=<VarBackward0>)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var = out.var(dim=-1, keepdim = True)\n",
    "var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "dacb3bdd-38fe-4e9f-a2f8-235d64585929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000],\n",
       "        [1.0000]], grad_fn=<VarBackward0>)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normed = ((out-mean) / torch.sqrt(var))\n",
    "normed.var(dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8065b5b2-8cb3-44c0-a134-24eaea1833e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "914fca95-3d78-426e-96fa-d96d3daeb033",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        # self.shift = 0, in training if network learns that certain values help it learn (like the mean) itll change its value\n",
    "        return self.scale * norm_x + self.shift\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d003a099-3bd6-4527-9d2a-596abe8d6cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ln = LayerNorm(100)\n",
    "outputs_normed = ln(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "86d2b4c0-88b6-4ad4-b6d3-912b3e7ff6ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7699, -0.7699,  1.7733,  1.1009, -0.7699, -0.7699,  1.0319, -0.7699,\n",
       "         -0.0824, -0.7699,  0.9400, -0.2331,  0.3949,  1.3652,  2.0988, -0.7699,\n",
       "         -0.6284, -0.5973,  0.7079, -0.7699, -0.7699, -0.7699, -0.7699, -0.7699,\n",
       "          0.3055, -0.7699, -0.7699,  2.0579, -0.2369, -0.7699, -0.7699,  1.4725,\n",
       "         -0.5859, -0.7699,  0.0413, -0.7699, -0.7699, -0.6651,  0.2958, -0.6374,\n",
       "          0.8969,  0.6662, -0.5361,  0.1909, -0.2360,  1.8692, -0.7699, -0.1595,\n",
       "         -0.7699, -0.7699,  2.3856,  0.9173,  1.4446, -0.7699, -0.7699, -0.5294,\n",
       "          1.0268,  0.5324, -0.7699, -0.7699,  1.4190,  1.5587,  2.0134, -0.7699,\n",
       "         -0.7699,  2.2218, -0.7699, -0.7699,  2.2776, -0.7699,  2.4889, -0.7699,\n",
       "         -0.2936, -0.7699,  0.6001, -0.7699, -0.7699, -0.7699, -0.0415, -0.7699,\n",
       "          1.0233, -0.7699, -0.4284, -0.7699,  1.4674,  1.6968,  1.1964, -0.7699,\n",
       "         -0.7699, -0.7699, -0.7699,  0.4329, -0.7699, -0.7699, -0.6145, -0.7699,\n",
       "          0.0179,  1.1066, -0.7699, -0.3453],\n",
       "        [-0.7386, -0.7386,  2.2893, -0.2104,  1.0661,  1.9927, -0.7386, -0.7386,\n",
       "         -0.7386,  2.5033,  0.1219, -0.0316, -0.7386, -0.7386, -0.1580, -0.3585,\n",
       "         -0.5425, -0.7386, -0.7386, -0.0790, -0.4568, -0.7386,  0.6893,  2.9160,\n",
       "          1.1679,  0.5354, -0.7386,  2.0924,  0.8095, -0.2751, -0.7386,  0.0588,\n",
       "         -0.4042, -0.7386,  0.0058,  1.2181, -0.7386, -0.7386, -0.7386,  0.5525,\n",
       "         -0.7386,  0.2362,  0.0735, -0.7386, -0.7386, -0.7386, -0.7386, -0.7386,\n",
       "          1.8332,  1.0064, -0.7386,  1.0673, -0.7386, -0.7386,  0.7138, -0.7386,\n",
       "         -0.7386, -0.0121, -0.7386,  1.8249,  0.0657, -0.7386, -0.1128, -0.6538,\n",
       "         -0.7386, -0.7386, -0.7386, -0.7386, -0.0287, -0.7386, -0.7386,  0.9281,\n",
       "         -0.2508,  0.5001,  0.7044,  2.1619, -0.4771, -0.7386, -0.7386,  0.8757,\n",
       "         -0.7386, -0.1153,  0.6185,  0.0784, -0.7386, -0.5793, -0.7386, -0.2967,\n",
       "         -0.7386,  0.6750, -0.6248,  0.0587, -0.7386, -0.7386,  0.6628,  0.2183,\n",
       "          1.0837, -0.7386,  0.2470,  4.5125]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c3dc9d34-d9fe-46ed-8a40-d8eca2af1d66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[     0.0000],\n",
       "        [    -0.0000]], grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_normed.mean(dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8c17c99b-9bc7-4855-850b-9b2ddc03bef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0100],\n",
       "        [1.0100]], grad_fn=<VarBackward0>)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_normed.var(dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58424682-4b4a-4ffe-8a31-6c94ce2c7f44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4d8fcb-ba36-4ce5-a531-98238a14a2f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
